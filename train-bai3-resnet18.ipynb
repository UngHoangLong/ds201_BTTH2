{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13453298,"sourceType":"datasetVersion","datasetId":8539588}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -rf /kaggle/working/ds201_BTTH2\n!git clone https://github.com/UngHoangLong/ds201_BTTH2.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom sklearn.metrics import precision_score, recall_score, f1_score\nimport matplotlib.pyplot as plt\n\nimport sys\nsys.path.append(\"/kaggle/working/ds201_BTTH2\")\n\nfrom data_loader import get_vinfood_dataloaders\nfrom module import ResNet18\nfrom tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T06:32:10.057121Z","iopub.execute_input":"2025-11-06T06:32:10.057351Z","iopub.status.idle":"2025-11-06T06:32:10.061786Z","shell.execute_reply.started":"2025-11-06T06:32:10.057324Z","shell.execute_reply":"2025-11-06T06:32:10.061131Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"train_data_path = \"/kaggle/input/vinafood21/VinaFood21/train\"\ntest_data_path = \"/kaggle/input/vinafood21/VinaFood21/test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T06:32:17.224467Z","iopub.execute_input":"2025-11-06T06:32:17.225267Z","iopub.status.idle":"2025-11-06T06:32:17.228571Z","shell.execute_reply.started":"2025-11-06T06:32:17.225241Z","shell.execute_reply":"2025-11-06T06:32:17.227765Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"BATCH_SIZE = 16\nRESNET18_IMG_SIZE = 224\ntrain_loader, val_loader, test_loader, NUM_CLASSES = get_vinfood_dataloaders(batch_size=BATCH_SIZE, train_path=train_data_path, test_path=test_data_path, val_split=0.2, image_size=RESNET18_IMG_SIZE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T06:32:19.122880Z","iopub.execute_input":"2025-11-06T06:32:19.123179Z","iopub.status.idle":"2025-11-06T06:32:58.842520Z","shell.execute_reply.started":"2025-11-06T06:32:19.123156Z","shell.execute_reply":"2025-11-06T06:32:58.841720Z"}},"outputs":[{"name":"stdout","text":"Đã tải data thành công. Tổng cộng 21 lớp.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Cấu hình\nLEARNING_RATE = 0.001 # theo tiêu chuẩn của Adam optimizer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Sử dụng thiết bị: {device}\")\n\n# Khởi tạo model với đúng số lớp\nmodel = ResNet18(num_classes=NUM_CLASSES).to(device)\n\n# Hàm loss\ncriterion = nn.CrossEntropyLoss()\n\n# Optimizer Adam theo yêu cầu\noptimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n\nprint(\"Đã khởi tạo model, criterion, và optimizer.\")\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T06:33:23.405952Z","iopub.execute_input":"2025-11-06T06:33:23.406575Z","iopub.status.idle":"2025-11-06T06:33:23.870147Z","shell.execute_reply.started":"2025-11-06T06:33:23.406549Z","shell.execute_reply":"2025-11-06T06:33:23.869534Z"}},"outputs":[{"name":"stdout","text":"Sử dụng thiết bị: cuda\nĐã khởi tạo model, criterion, và optimizer.\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (shortcut): Sequential()\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=21, bias=True)\n)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"NUM_EPOCHS = 50 # Số epochs bạn muốn chạy\nhistory = {'train_loss': [], 'val_f1': [], 'val_precision': [], 'val_recall': []}\n\n# --- THÊM MỚI: Biến để theo dõi model tốt nhất ---\nbest_val_f1 = 0.0  # Bắt đầu với F1 = 0\nMODEL_SAVE_PATH = \"best_resnet18_model.pth\" # Tên file để lưu model\n# -----------------------------------------------\n\nprint('Bắt đầu quá trình huấn luyện')\nfor epoch in range(NUM_EPOCHS):\n    \n    # --- Training ---\n    model.train()\n    running_loss = 0.0 # biến này lưu trữ loss của từng epoch\n    \n    train_progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - Train', leave=False)\n    \n    for images, labels in train_progress_bar: # Lặp qua progress bar mới\n        # print('bắt đầu batch') # Bạn có thể bỏ comment này nếu muốn xem chi tiết\n        images, labels = images.to(device), labels.to(device)\n\n        output = model(images) # chạy def forward\n        loss = criterion(output, labels) #\n\n        optimizer.zero_grad() # xoá grad của batch cũ\n        loss.backward() # tính toán gradient (tìm đường xuống dốc)\n        optimizer.step() # Cập nhật trọng số (bước xuống dốc)\n        running_loss += loss.item() # \n        \n        train_progress_bar.set_postfix(batch_loss=loss.item())\n\n    epoch_train_loss = running_loss / len(train_loader) # tổng loss chia cho tổng số batch\n    history['train_loss'].append(epoch_train_loss)\n\n    # --- Validation ---\n    model.eval()\n    val_preds=[]\n    val_labels=[]\n    \n    val_progress_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS} - Val', leave=False)\n    \n    with torch.no_grad(): # không theo dõi hay tính gradient gì \n        for images, labels in val_progress_bar: # Lặp qua progress bar mới\n            images, labels = images.to(device), labels.to(device)\n            output = model(images)\n            _, predicted = torch.max(output.data, 1) # không cần softmax vì logits lớn thì xác xuất cũng lớn\n\n            val_preds.extend(predicted.cpu().numpy())\n            val_labels.extend(labels.cpu().numpy())\n\n    # Tính metrics trên tập Validation\n    precision = precision_score(val_labels, val_preds, average='macro', zero_division=0)\n    recall = recall_score(val_labels, val_preds, average='macro', zero_division=0)\n    f1 = f1_score(val_labels, val_preds, average='macro', zero_division=0)\n    \n    history['val_precision'].append(precision)\n    history['val_recall'].append(recall)\n    history['val_f1'].append(f1)\n    \n    # Print kết quả của tập Validation\n    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Train Loss: {epoch_train_loss:.4f} | Val F1 (Macro): {f1:.4f}\")\n\n    # --- THÊM MỚI: Logic lưu model ---\n    if f1 > best_val_f1:\n        best_val_f1 = f1 # Cập nhật F1 tốt nhất\n        # Lưu lại \"trạng thái\" (state_dict) của model\n        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n        print(f\"  -> Đã lưu model tốt nhất mới! F1: {best_val_f1:.4f} tại {MODEL_SAVE_PATH}\")\n    # ------------------------------------\n\nprint(f\"\\nHuấn luyện hoàn tất! F1 tốt nhất trên Validation là: {best_val_f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T06:33:28.531224Z","iopub.execute_input":"2025-11-06T06:33:28.531808Z","iopub.status.idle":"2025-11-06T07:56:20.457892Z","shell.execute_reply.started":"2025-11-06T06:33:28.531780Z","shell.execute_reply":"2025-11-06T07:56:20.456701Z"}},"outputs":[{"name":"stdout","text":"Bắt đầu quá trình huấn luyện\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50 - Train Loss: 2.8148 | Val F1 (Macro): 0.1438\n  -> Đã lưu model tốt nhất mới! F1: 0.1438 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 2/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/50 - Train Loss: 2.5230 | Val F1 (Macro): 0.1969\n  -> Đã lưu model tốt nhất mới! F1: 0.1969 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 3/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3/50 - Train Loss: 2.3249 | Val F1 (Macro): 0.2232\n  -> Đã lưu model tốt nhất mới! F1: 0.2232 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 4/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4/50 - Train Loss: 2.2096 | Val F1 (Macro): 0.2554\n  -> Đã lưu model tốt nhất mới! F1: 0.2554 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 5/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 5/50 - Train Loss: 2.0778 | Val F1 (Macro): 0.2699\n  -> Đã lưu model tốt nhất mới! F1: 0.2699 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 6/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 6/50 - Train Loss: 1.9763 | Val F1 (Macro): 0.3298\n  -> Đã lưu model tốt nhất mới! F1: 0.3298 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 7/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 7/50 - Train Loss: 1.8909 | Val F1 (Macro): 0.3359\n  -> Đã lưu model tốt nhất mới! F1: 0.3359 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 8/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 8/50 - Train Loss: 1.7814 | Val F1 (Macro): 0.3689\n  -> Đã lưu model tốt nhất mới! F1: 0.3689 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 9/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 9/50 - Train Loss: 1.6744 | Val F1 (Macro): 0.3775\n  -> Đã lưu model tốt nhất mới! F1: 0.3775 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 10/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 10/50 - Train Loss: 1.5742 | Val F1 (Macro): 0.4127\n  -> Đã lưu model tốt nhất mới! F1: 0.4127 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 11/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 11/50 - Train Loss: 1.4438 | Val F1 (Macro): 0.4221\n  -> Đã lưu model tốt nhất mới! F1: 0.4221 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 12/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 12/50 - Train Loss: 1.3231 | Val F1 (Macro): 0.4621\n  -> Đã lưu model tốt nhất mới! F1: 0.4621 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 13/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 13/50 - Train Loss: 1.1606 | Val F1 (Macro): 0.4622\n  -> Đã lưu model tốt nhất mới! F1: 0.4622 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 14/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 14/50 - Train Loss: 1.0048 | Val F1 (Macro): 0.4665\n  -> Đã lưu model tốt nhất mới! F1: 0.4665 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 15/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 15/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 15/50 - Train Loss: 0.8195 | Val F1 (Macro): 0.4787\n  -> Đã lưu model tốt nhất mới! F1: 0.4787 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 16/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 16/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 16/50 - Train Loss: 0.6124 | Val F1 (Macro): 0.4964\n  -> Đã lưu model tốt nhất mới! F1: 0.4964 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 17/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9995ddf92854955a2fc0a5c776a8d83"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 17/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"717552bd5be84188a7c73346c82f138e"}},"metadata":{}},{"name":"stdout","text":"Epoch 17/50 - Train Loss: 0.4421 | Val F1 (Macro): 0.4879\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 18/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"167a18bccd164f8f9402f4a81e500029"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 18/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"900f4edb800541b39d46f5780517f637"}},"metadata":{}},{"name":"stdout","text":"Epoch 18/50 - Train Loss: 0.3164 | Val F1 (Macro): 0.5107\n  -> Đã lưu model tốt nhất mới! F1: 0.5107 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 19/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91416a0fe9414247b5f235f2851445a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 19/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7040e60c9994bb3a7021f97367df1cc"}},"metadata":{}},{"name":"stdout","text":"Epoch 19/50 - Train Loss: 0.2708 | Val F1 (Macro): 0.4529\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 20/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a567c5e028d4941a3d949981eee9f81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 20/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b96ff3e794dc4587a0874807914cacee"}},"metadata":{}},{"name":"stdout","text":"Epoch 20/50 - Train Loss: 0.1984 | Val F1 (Macro): 0.5019\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 21/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d79fd10f60974c3883ea5e274c0adebf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 22/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 22/50 - Train Loss: 0.1419 | Val F1 (Macro): 0.4939\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 23/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 23/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 23/50 - Train Loss: 0.1514 | Val F1 (Macro): 0.5018\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 24/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 24/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 24/50 - Train Loss: 0.1214 | Val F1 (Macro): 0.5123\n  -> Đã lưu model tốt nhất mới! F1: 0.5123 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 25/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 25/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 25/50 - Train Loss: 0.0895 | Val F1 (Macro): 0.5390\n  -> Đã lưu model tốt nhất mới! F1: 0.5390 tại best_resnet18_model.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 26/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 26/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 26/50 - Train Loss: 0.0815 | Val F1 (Macro): 0.4965\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 27/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 27/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 27/50 - Train Loss: 0.1290 | Val F1 (Macro): 0.4626\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 28/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 28/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 28/50 - Train Loss: 0.1016 | Val F1 (Macro): 0.5076\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 29/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 29/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 29/50 - Train Loss: 0.1104 | Val F1 (Macro): 0.5367\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 30/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 30/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 30/50 - Train Loss: 0.0550 | Val F1 (Macro): 0.4786\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 31/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 31/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 31/50 - Train Loss: 0.1040 | Val F1 (Macro): 0.4881\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 32/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 32/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 32/50 - Train Loss: 0.0650 | Val F1 (Macro): 0.5153\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 33/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 33/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 33/50 - Train Loss: 0.0699 | Val F1 (Macro): 0.5044\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 34/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 34/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 34/50 - Train Loss: 0.0747 | Val F1 (Macro): 0.5085\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 35/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 35/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 35/50 - Train Loss: 0.0720 | Val F1 (Macro): 0.4728\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 36/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 36/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 36/50 - Train Loss: 0.0545 | Val F1 (Macro): 0.5009\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 37/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 37/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 37/50 - Train Loss: 0.0904 | Val F1 (Macro): 0.5206\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 38/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 38/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 38/50 - Train Loss: 0.0706 | Val F1 (Macro): 0.5378\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 39/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 39/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 39/50 - Train Loss: 0.0669 | Val F1 (Macro): 0.5222\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 40/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 40/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 40/50 - Train Loss: 0.0412 | Val F1 (Macro): 0.5086\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 41/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 41/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 41/50 - Train Loss: 0.0914 | Val F1 (Macro): 0.5239\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 42/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 42/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 42/50 - Train Loss: 0.0325 | Val F1 (Macro): 0.5359\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 43/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 43/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 43/50 - Train Loss: 0.0385 | Val F1 (Macro): 0.4892\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 44/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 44/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 44/50 - Train Loss: 0.0776 | Val F1 (Macro): 0.4715\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 45/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 45/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 45/50 - Train Loss: 0.0316 | Val F1 (Macro): 0.5145\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 46/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 46/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 46/50 - Train Loss: 0.0591 | Val F1 (Macro): 0.5115\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 47/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 47/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 47/50 - Train Loss: 0.0519 | Val F1 (Macro): 0.5098\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 48/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 48/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 48/50 - Train Loss: 0.0767 | Val F1 (Macro): 0.5105\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 49/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 49/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 49/50 - Train Loss: 0.0347 | Val F1 (Macro): 0.5216\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 50/50 - Train:   0%|          | 0/503 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 50/50 - Val:   0%|          | 0/126 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 50/50 - Train Loss: 0.0278 | Val F1 (Macro): 0.5073\n\nHuấn luyện hoàn tất! F1 tốt nhất trên Validation là: 0.5390\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# (Cell 5 - Đánh giá cuối cùng trên tập Test)\n\nprint(\"Đang đánh giá kết quả cuối cùng trên tập Test...\")\n\n# 1. Khởi tạo lại kiến trúc model (phải giống hệt)\n# Đảm bảo `LeNet` và `NUM_CLASSES` đã được định nghĩa ở các cell trên\ntest_model = ResNet18(num_classes=NUM_CLASSES).to(device)\n\n# 2. Tải trọng số (weights) đã lưu từ file\ntest_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n\n# 3. Chuyển sang chế độ đánh giá\ntest_model.eval()\n\ntest_preds = []\ntest_labels = []\n\n# Thêm tqdm cho vòng lặp test\ntest_progress_bar = tqdm(test_loader, desc=\"Testing\", leave=False)\n\nwith torch.no_grad(): # không theo dõi hay tính gradient gì \n    for images, labels in test_progress_bar:\n        images, labels = images.to(device), labels.to(device)\n        \n        # Dùng test_model (đã được tải) để dự đoán\n        outputs = test_model(images)\n        \n        _, predicted = torch.max(outputs.data, 1) # không cần softmax\n        \n        test_preds.extend(predicted.cpu().numpy())\n        test_labels.extend(labels.cpu().numpy())\n\n# Tính toán các độ đo cuối cùng\ntest_precision = precision_score(test_labels, test_preds, average='macro', zero_division=0)\ntest_recall = recall_score(test_labels, test_preds, average='macro', zero_division=0)\ntest_f1 = f1_score(test_labels, test_preds, average='macro', zero_division=0)\n\nprint(\"\\n--- KẾT QUẢ CUỐI CÙNG TRÊN TẬP TEST (từ model tốt nhất) ---\")\nprint(f\"Test Precision (Macro): {test_precision:.4f}\")\nprint(f\"Test Recall (Macro):    {test_recall:.4f}\")\nprint(f\"Test F1-Score (Macro):  {test_f1:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-06T07:57:01.047853Z","iopub.execute_input":"2025-11-06T07:57:01.048146Z","iopub.status.idle":"2025-11-06T07:58:39.937964Z","shell.execute_reply.started":"2025-11-06T07:57:01.048116Z","shell.execute_reply":"2025-11-06T07:58:39.936956Z"}},"outputs":[{"name":"stdout","text":"Đang đánh giá kết quả cuối cùng trên tập Test...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing:   0%|          | 0/418 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"\n--- KẾT QUẢ CUỐI CÙNG TRÊN TẬP TEST (từ model tốt nhất) ---\nTest Precision (Macro): 0.4908\nTest Recall (Macro):    0.4584\nTest F1-Score (Macro):  0.4606\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"### Tại sao ResNet-18 tốt hơn GoogLeNet (khi huấn luyện \"từ đầu\")?\n\nMặc dù cả hai đều là mạng sâu, ResNet-18 có 2 \"vũ khí\" mà GoogLeNet-v1 (2014) không có:\n\n1.  **Batch Normalization (BatchNorm):**\n    * Đây là lý do **quan trọng nhất**. ResNet-18 có một lớp `BatchNorm` sau *mỗi* lớp `Conv`.\n    * `BatchNorm` giúp \"ổn định\" dữ liệu giữa các lớp, cho phép mô hình hội tụ (học) **nhanh hơn và ổn định hơn rất nhiều**.\n    * GoogLeNet-v1 ra đời *trước* BatchNorm (2015) nên nó không có, khiến việc huấn luyện từ đầu cực kỳ khó khăn.\n\n2.  **Kết nối tắt (Residual Connections):**\n    * Phép cộng `out += identity` giúp gradient (tín hiệu \"học\") chảy ngược về các lớp đầu tiên một cách dễ dàng. Nó giải quyết vấn đề \"vanishing gradient\" (gradient biến mất) mà các mạng rất sâu thường gặp phải.\n\n---\n\n### Hướng đi tiếp theo\n\nMặc dù 0.46 là tốt (so với 0.0079), nó vẫn chưa phải là kết quả tốt nhất. Lý do là chúng ta vẫn đang **huấn luyện từ đầu (from scratch)**.\n\nGiải pháp để đạt kết quả cao hơn (ví dụ: F1 > 0.9) là sử dụng **Học Chuyển giao (Transfer Learning)**, bằng cách tải một mô hình ResNet-18 đã được huấn luyện trước (`pretrained=True`).","metadata":{}}]}